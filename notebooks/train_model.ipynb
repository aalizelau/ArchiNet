{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39446ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install uv\n",
    "!uv pip install timm\n",
    "!uv pip install scikit-learn\n",
    "!uv pip install matplotlib\n",
    "!uv pip install tqdm\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8de3ad",
   "metadata": {},
   "source": [
    "### Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3db7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload kaggle.json\n",
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b496912",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p ~/.kaggle\n",
    "mv /content/kaggle.json ~/.kaggle/\n",
    "chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d dumitrux/architectural-styles-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d337c1c",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd97d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((384, 384)),  # match model input\n",
    "    transforms.ToTensor(),          # convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder('./architectural-styles-dataset', transform=transform)\n",
    "print(dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590d2079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/test\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Define sizes\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size  # to ensure total size is preserved\n",
    "\n",
    "# Split dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Print sizes\n",
    "print(f\"Train size: {len(train_dataset)}, Validation size: {len(val_dataset)}, Test size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca84d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, num_workers=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, num_workers=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84c29f2",
   "metadata": {},
   "source": [
    "### Model Creation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f7547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextViTPotatoClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model('nextvit_small.bd_ssld_6m_in1k_384', pretrained=True)\n",
    "        self.backbone.head = nn.Linear(self.backbone.head.in_features, 25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone.forward_features(x)\n",
    "        features = features.mean(dim=[2, 3])\n",
    "        return self.backbone.head(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d99e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NextViTPotatoClassifier().to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # freeze everything\n",
    "\n",
    "# Unfreeze only the classifier head\n",
    "for param in model.backbone.head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.backbone.head.parameters(), lr=4e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0defe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show trainable parameters\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142c5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_head_weights(model):\n",
    "    for layer in model.backbone.head.modules():\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            layer.reset_parameters()\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in dataloader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, pred_classes = torch.max(probs, dim=1)\n",
    "            correct += (pred_classes == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d701c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Training loop\n",
    "reset_head_weights(model)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    # Show progress bar per epoch\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "    for imgs, labels in loop:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Track accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "\n",
    "        # Update tqdm status bar\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    train_acc = train_correct / train_total\n",
    "    val_acc = evaluate(model, val_loader)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "          f\"Train Acc: {train_acc:.2%} | Val Acc: {val_acc:.2%}\")\n",
    "\n",
    "    # Save checkpoint\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94744403",
   "metadata": {},
   "source": [
    "### Model Evaluation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e51a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = evaluate(model, test_loader)\n",
    "print(f\"Testing Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d253be57",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6de81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff354c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ONNX\n",
    "model.eval()\n",
    "dummy_input = torch.randn(1, 3, 384, 384).to(device)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"archinet.onnx\",           # output file name\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}},\n",
    "    opset_version=16,\n",
    "    verbose=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
